# Schema Synchronization Guide

## Overview

The UnrealMCPProxy maintains cached tool definitions in `src/unreal_mcp_proxy/tool_definitions.py` that must be **compatible** with the schemas generated by the UnrealMCPServer backend. This guide covers the compatibility-based approach to schema synchronization.

**Important**: This project underwent a major refactor moving from **exact schema matching** to a **compatibility-based approach**. Synchronization is still required, but the requirements are different and more flexible.

### The Compatibility-Based Approach

**Key Principle**: Proxy schemas don't need to exactly match backend schemas. They must be **compatible**, meaning:
- All required backend fields must be present in proxy schemas
- Field types must be compatible (e.g., `number` and `integer` are compatible)
- Property names must match exactly for required fields
- Proxy can have improved descriptions, simplified types, better defaults, and additional optional fields

**What Changed:**
- ❌ **Old approach**: Proxy schemas had to exactly match backend schemas (descriptions, defaults, types, etc.)
- ✅ **New approach**: Proxy schemas must be compatible (required fields present, types compatible), but can be improved

**Why This Matters:**
- The proxy is the **authoritative source** for the user-facing API
- Proxy can provide better UX with improved descriptions and defaults
- Backend remains the source of truth for required fields and type constraints
- Compatibility checking ensures proxy schemas work correctly with backend

## Table of Contents

1. [Understanding Schema Generation](#understanding-schema-generation)
2. [Best Practices](#best-practices)
3. [Common Pitfalls](#common-pitfalls)
4. [Testing and Validation](#testing-and-validation)
5. [Update Workflow](#update-workflow)
6. [Troubleshooting](#troubleshooting)

## Understanding Schema Generation

### Backend Schema Generation

The backend generates JSON schemas from C++ USTRUCT definitions using `UMCP_GenerateJsonSchemaFromStruct`. Key behaviors:

1. **Property Names**: Converted to camelCase (e.g., `bRecursive` → `bRecursive`, `timeoutSeconds` → `timeoutSeconds`)
2. **Default Values**: Extracted from default-constructed USTRUCT instances
   - Empty strings are **not** included as defaults
   - Empty arrays **are** included as defaults (`[]`)
   - Numbers, booleans, and objects are included as defaults
3. **Required Fields**: Determined by:
   - Explicit `RequiredFields` parameter in schema generation
   - Or all fields are required if no explicit list is provided
4. **Nested Structs**: Marked as `"type": "object"` without expanding properties
   - Default values for nested objects are included as full JSON objects
5. **Descriptions**: Extracted from:
   - Explicit `PropertyDescriptions` map (preferred)
   - UPROPERTY metadata (`ToolTip` or `Description`)
   - Or omitted if not available

### Proxy Schema Compatibility

The proxy's cached schemas must be **compatible** with the backend's generated schemas. The compatibility check (implemented in `compare_tool_definitions()`) verifies:

**Required (Must Match):**
- **Tool names**: Must match exactly
- **Required fields**: All backend required fields must be present in proxy schemas
- **Field names**: Required field names must match exactly (camelCase from USTRUCT)
- **Field types**: Types must be compatible (see compatible types below)

**Optional (Proxy Can Improve):**
- **Descriptions**: Proxy can have better, more detailed descriptions
- **Simplified types**: Proxy can use simpler types (e.g., `string` instead of `enum` with one value)
- **Better defaults**: Proxy can provide more sensible default values
- **Additional optional fields**: Proxy can include extra optional fields (backend will ignore them)
- **Empty required arrays**: Proxy can include or omit `"required": []` as needed

**Compatible Types:**
The compatibility checker recognizes these type groups as compatible:
- `{"number", "integer"}` - Numbers and integers are compatible
- `{"string"}` - Strings are always compatible
- `{"boolean"}` - Booleans are always compatible
- `{"array"}` - Arrays are compatible
- `{"object"}` - Objects are compatible

**Note**: Types within the same group are compatible, but types from different groups are not (e.g., `number` and `string` are incompatible).

## Best Practices

### 1. Always Use the Test Suite

**Before committing schema changes:**
```bash
cd UnrealMCPProxy
uv --directory . run test_proxy.py
```

The test suite will:
- Query the backend for actual schemas
- Check compatibility with cached definitions
- Show compatibility issues (missing required fields, type mismatches)
- Report missing or extra tools

**Never skip this step** - it's the only reliable way to detect compatibility issues.

### 2. Update Both Sides Together (But Proxy Can Improve)

When modifying backend tool definitions:
1. Update the C++ USTRUCT definitions in the backend
2. Update the proxy's tool definitions in the appropriate domain file:
   - Common Tools → `tool_definitions_common.py`
   - Asset Tools → `tool_definitions_asset.py`
   - Blueprint Tools → `tool_definitions_blueprint.py`
3. **Ensure compatibility** (required fields present, types compatible)
4. **Improve where possible** (better descriptions, simpler types, better defaults)
5. Run the test suite to verify compatibility
6. Commit both changes together

**Remember**: You don't need to copy backend schemas exactly. Focus on compatibility, then improve the user experience.

### 3. Use Compatibility Check Output

The compatibility checker (`compare_tool_definitions()`) reports specific issues:
- **Missing required fields**: Lists fields that backend requires but proxy doesn't have
- **Type mismatches**: Shows incompatible types for required fields
- **Name mismatches**: Tool names that don't match

When the test suite or runtime compatibility check reports issues, it shows:
- Detailed error messages for each issue
- Full schema dumps for the first incompatible tool (for debugging)
- Clear guidance on what needs to be fixed

**Use this output to fix compatibility issues**. Remember: proxy schemas can differ from backend as long as they're compatible. The compatibility checker will tell you exactly what needs to match.

### 4. Understand Default Value Rules

**Backend Default Behavior:**
The backend generates defaults from C++ USTRUCT default-constructed instances:
- Empty arrays: `"default": []` (included)
- Numbers with explicit defaults: `"default": 0`, `"default": 300` (included)
- Booleans with explicit defaults: `"default": false`, `"default": true` (included)
- Nested objects with non-empty defaults: `"default": {...}` (included)
- Empty strings: Not included (not meaningful defaults)
- Non-empty arrays: Not included (too complex)

**Proxy Default Behavior:**
- **Proxy can have different defaults** than backend
- Proxy applies its own defaults when forwarding requests
- Proxy defaults are what users see in tool definitions
- Backend defaults serve as a safety net for direct backend calls
- **Compatibility check doesn't verify defaults match** - they can differ

**Best Practice**: Use proxy defaults that make sense for the user-facing API, even if they differ from backend defaults.

### 5. Include All Required Fields

All backend required fields must be present in proxy schemas:
- If backend has `"required": ["field1", "field2"]`, proxy must include both fields
- Proxy can have additional optional fields (backend will ignore them)
- Order doesn't matter

**Special Case: Conditional Requirements (At Least One Of)**

Some tools have conditional requirements where at least one of multiple fields must be specified, but none are individually required in the JSON schema. For example, `search_assets` requires at least one of `packagePaths` or `packageNames` to be non-empty.

**Important**: For conditional requirements, the proxy should mark these fields as required for better agent UX:
- **Mark both fields as required** in the proxy schema (even though backend doesn't)
- This prevents agents from leaving both fields empty (which would cause runtime errors)
- Fields should have defaults (typically empty arrays `[]`) for schema validity
- **Tool description** must clearly state: "REQUIRED: At least one of X or Y must be provided"
- **Field descriptions** should explain the conditional relationship: "At least one of packagePaths or packageNames must be provided"
- Backend validates this at runtime, but marking as required in proxy schema guides agents upfront

**Rationale**: Agents tend to call tools with all optional arguments left blank. By marking conditionally required fields as required in the proxy schema, agents are prompted to consider these fields, improving tool utilization and reducing errors.

See [Common Pitfalls: Conditional Requirements (At Least One Of)](#5-conditional-requirements-at-least-one-of) for detailed guidance.

### 6. Handle Nested Objects Correctly

For nested structs in output schemas:
- Type: `"type": "object"` (not expanded)
- Include default if backend includes it: `"default": {...}`
- Don't expand nested properties in the schema

Example:
```python
"engineVersion": {
    "type": "object",
    "description": "Engine version information",
    "default": {
        "changelist": 0,
        "full": "",
        "major": 0,
        "minor": 0,
        "patch": 0
    }
}
```

### 7. Preserve Field Order (Optional but Helpful)

While field order doesn't affect functionality, maintaining a consistent order makes diffs easier to read:
- Input schemas: required fields first, then optional
- Output schemas: success/status fields first, then data fields, then error fields

## Common Pitfalls

### 1. Missing Required Fields

**Problem**: Proxy schema doesn't include all required backend fields.

**Example**: Backend requires `["objectPath", "format"]` but proxy only has `["objectPath"]`.

**Solution**: Ensure all backend required fields are present in proxy schemas. Use the test suite to detect missing fields.

### 2. Type Incompatibility

**Problem**: Proxy field type is incompatible with backend type.

**Example**: Backend requires `"type": "number"` but proxy has `"type": "string"`.

**Solution**: Ensure field types are compatible. Compatible types: `number`/`integer`, `string`, `boolean`, `array`, `object`.

### 3. Field Name Mismatches

**Problem**: Required field name doesn't match between proxy and backend.

**Example**: Backend requires `bRecursive` but proxy has `recursive`.

**Solution**: Required field names must match exactly. The backend uses camelCase from USTRUCT properties.

### 4. Conditional Features

**Problem**: Not updating tool definitions when conditional features change.

**Solution**: When markdown export support is enabled/disabled, ensure tool descriptions are updated. Use the `enable_markdown_export` parameter in `get_tool_definitions()`.

### 5. Conditional Requirements (At Least One Of)

**Problem**: Some tools have conditional requirements where at least one of multiple fields must be specified, but none are individually required in the JSON schema. Agents tend to leave optional fields blank, leading to runtime errors when both conditional fields are empty.

**Example**: The `search_assets` tool requires at least one of `packagePaths` or `packageNames` to be a non-empty array, but neither is marked as required in the backend schema (they have defaults of `[]`).

**Backend Behavior**:
- Fields are not in the `required` array in the JSON schema
- Fields have default values (typically empty arrays `[]`)
- Runtime validation checks that at least one field is non-empty
- Backend descriptions use conditional language: "REQUIRED (if otherField is empty)"
- Backend returns error if both are empty: "Missing required parameter: Either packagePaths or packageNames must be provided"

**Proxy Handling (UX Improvement)**:
- **Mark both fields as required** in the proxy schema (even though backend doesn't)
- This is a proxy improvement - agents interact with proxy schema, so marking as required guides them
- **Include defaults** (empty arrays `[]`) for schema validity, but marking as required ensures agents consider them
- **Include clear descriptions** that explain the conditional requirement:
  - "At least one of `packagePaths` or `packageNames` must be provided (non-empty array)"
  - Tool description should state: "REQUIRED: At least one of 'packagePaths' or 'packageNames' must be a non-empty array"
- **Field descriptions** should mention the relationship: "At least one of packagePaths or packageNames must be provided"

**Why This Matters**:
- **Agent Behavior**: Agents tend to call tools with all optional arguments left blank
- **Error Prevention**: Marking as required prevents agents from leaving both fields empty
- **Better UX**: Agents are prompted to consider these fields upfront, improving tool utilization
- **Compatibility**: Proxy can have additional required fields - backend will accept them (with defaults if needed)
- This pattern may be used in other tools with similar conditional logic

**Example from `search_assets` (Proxy Implementation)**:
```python
    "packagePaths": {
        "type": "array",
        "items": {"type": "string"},
        "description": "Array of directory/package paths to search for assets. Examples: ['/Game/Blueprints', '/Game/Materials']. At least one of packagePaths or packageNames must be provided. For large directories, use maxResults and offset for paging.",
        "default": []
    },
"packageNames": {
    "type": "array",
    "items": {"type": "string"},
    "description": "Array of package names to search for. Supports both exact matches and partial matches. Examples: ['MyAsset', '/Game/MyAsset'] for exact matches, ['BP_*', '*Player*', 'MyAsset'] for partial matches. Partial matching supports: (1) Wildcards: * (matches any characters) and ? (matches single character); (2) Substring matching: partial names without wildcards match if package name contains the substring (case-insensitive). NOTE: Partial searches require packagePaths or classPaths to define search scope. At least one of packagePaths or packageNames must be provided.",
    "default": []
},
"required": [
    "packagePaths",  # Marked as required in proxy (UX improvement)
    "packageNames",  # Marked as required in proxy (UX improvement)
    # ... other fields
]
# Tool description: "REQUIRED: At least one of 'packagePaths' or 'packageNames' must be a non-empty array."
```

**Best Practice**: When handling conditional requirements:
1. **Mark both fields as required** in proxy schema (improves agent UX)
2. Include defaults (empty arrays) for schema validity
3. Use clear language in descriptions: "At least one of X or Y must be provided"
4. State the requirement prominently in the tool description
5. This is a case where proxy improves on backend schema for better agent interaction

### 6. Partial Package Name Search Support

**Feature**: The `search_assets` tool supports partial package name matching in addition to exact matches. This allows searching for assets using wildcards or substring patterns.

**How It Works**:
- **Exact Matches**: Full package names (e.g., `/Game/Blueprints/BP_Player`) are matched directly using Unreal's asset registry
- **Partial Matches**: Package names with wildcards or partial patterns are detected and filtered post-search
  - **Wildcard Matching**: Supports `*` (matches any characters) and `?` (matches single character)
    - Example: `BP_*` matches all packages starting with `BP_`
    - Example: `*Player*` matches any package containing `Player`
  - **Substring Matching**: Partial names without wildcards use case-insensitive substring matching
    - Example: `Player` matches `/Game/Blueprints/BP_Player`
    - Example: `MyAsset` matches `/Game/MyAsset` and `/Game/Blueprints/MyAsset_Blueprint`

**Detection Logic**:
- A package name is considered "partial" if:
  - It contains wildcard characters (`*` or `?`), OR
  - It doesn't start with `/` (not a full package path)
- Full package paths starting with `/` are treated as exact matches unless they contain wildcards

**Important Requirements for Partial Searches**:
- **Partial package name searches require a search scope** to prevent expensive full asset registry scans
- Must provide at least one of:
  - `packagePaths`: Directory paths to search within (e.g., `['/Game/Blueprints']`)
  - `classPaths`: Class filters to limit asset types (e.g., `['/Script/Engine.Blueprint']`)
- If only partial `packageNames` are provided without `packagePaths` or `classPaths`, the backend will return an error: "Partial package name searches require either packagePaths or classPaths to define the search scope"

**Example Usage**:
```python
# Valid: Partial search with package path scope
search_assets(
    packagePaths=["/Game/Blueprints"],
    packageNames=["BP_*"],  # Find all Blueprints starting with "BP_"
    classPaths=["/Script/Engine.Blueprint"]
)

# Valid: Partial search with class filter scope
search_assets(
    packageNames=["*Player*"],  # Find any package containing "Player"
    classPaths=["/Script/Engine.Blueprint"]
)

# Invalid: Partial search without scope (will error)
search_assets(
    packageNames=["BP_*"]  # Missing packagePaths or classPaths
)

# Valid: Mix of exact and partial matches
search_assets(
    packagePaths=["/Game/Blueprints"],
    packageNames=["BP_Player", "BP_*", "*Enemy*"],  # Mix of exact and partial
    classPaths=["/Script/Engine.Blueprint"]
)
```

**Implementation Details**:
- Backend separates `packageNames` into exact matches and partial patterns
- Exact matches are added to the asset registry filter (efficient)
- Partial patterns are applied as post-filters on search results
- This hybrid approach balances performance (exact matches use registry filtering) with flexibility (partial matches support wildcards and substrings)

**Documentation Requirements**:
- Tool descriptions should clearly state: "Supports both exact matches and partial matches (wildcards * and ?, or substring matching)"
- Field descriptions should explain both wildcard and substring matching with examples
- Should warn about the requirement for `packagePaths` or `classPaths` when using partial searches

## What Changed: Compatibility vs Exact Matching

### What's No Longer Required (Compatibility-Based Approach)

With the compatibility-based approach, these are **no longer issues**:

- ✅ **Descriptions**: Proxy can have better descriptions than backend
- ✅ **Default values**: Proxy can have different defaults (proxy applies its own)
- ✅ **Optional fields**: Proxy can have additional optional fields (backend ignores them)
- ✅ **Type simplification**: Proxy can use simpler types (e.g., `string` instead of `enum` with one value)
- ✅ **Empty required arrays**: Proxy can include or omit `"required": []` as needed
- ✅ **Exact schema matching**: Proxy doesn't need to match backend schemas exactly

### What's Still Required (Compatibility Requirements)

These must still match for compatibility:

- ❗ **Tool names**: Must match exactly
- ❗ **Required fields**: All backend required fields must be present in proxy
- ❗ **Required field names**: Must match exactly (camelCase from USTRUCT)
- ❗ **Required field types**: Must be compatible (see compatible types above)

### Synchronization Still Required

**Important**: Even with the compatibility approach, **synchronization is still required** when:
- Backend adds new required fields → Proxy must add them
- Backend changes required field types → Proxy must update to compatible type
- Backend adds new tools → Proxy must add tool definitions
- Backend removes tools → Proxy should remove or mark as deprecated

The difference is that you have more flexibility in how you present the schemas to users, but you still need to keep required fields and types in sync.

## Testing and Validation

### Running the Test Suite

```bash
cd UnrealMCPProxy
uv --directory . run test_proxy.py
```

**Expected Output:**
- ✓ All tools defined in proxy cache
- ✓ Backend connection successful (if backend is online)
- ✓ Schema compatibility: All tools compatible, 0 issues

**Note**: The test suite uses the same `compare_tool_definitions()` function that runs at runtime, ensuring consistent compatibility checking.

### Interpreting Test Results

**All Compatible:**
```
✓ Compatible: 15
⚠ Compatibility issues: 0
```
✅ Safe to commit

**Compatibility Issues Detected:**
```
⚠ Compatibility issues: 5
```
❌ Fix compatibility issues before committing. The test will show detailed issues for the first 3 tools.

**Missing Tools:**
```
⚠ Missing in cache: 2
```
❌ New tools added to backend but not yet in proxy. Add them to `tool_definitions.py`.

**Extra Tools:**
```
⚠ Missing in backend: 1
```
⚠️ Tool removed from backend but still in cache. Remove it from `tool_definitions.py` or verify it's intentionally deprecated.

### Debugging Compatibility Issues

When a compatibility issue is detected, the compatibility checker (`compare_tool_definitions()`) provides:

1. **Tool name**: Which tool has the issue
2. **Issue type**: 
   - "Missing required fields in proxy schema: [field1, field2]"
   - "Type mismatch for required field 'fieldName': proxy='type1', backend='type2'"
   - "Name mismatch: proxy='name1', backend='name2'"
3. **Schema details**: Full schema dumps for the first incompatible tool (in runtime logs)

**Runtime Compatibility Checking:**
- Compatibility is checked automatically when backend comes online
- Warnings are logged for each incompatible tool
- First incompatible tool gets detailed schema dump in logs
- Proxy continues to work, but warnings indicate sync issues

**Test Suite Compatibility Checking:**
- Tests query backend and compare with proxy definitions
- Reports compatibility issues with detailed messages
- Shows count of compatible vs incompatible tools
- Lists missing tools (in backend but not proxy) and extra tools (in proxy but not backend)

Use this information to:
- Identify missing required fields
- Fix type incompatibilities
- Correct field name mismatches
- Add missing tools to proxy

## Update Workflow

### Understanding the Compatibility Checker

The compatibility checker (`compare_tool_definitions()` in `tool_definitions.py`) performs these checks:

1. **Tool Name Match**: Verifies tool names match exactly
2. **Required Fields Check**: Ensures all backend required fields exist in proxy
3. **Type Compatibility Check**: Verifies required field types are compatible
   - Uses compatible type groups: `{number, integer}`, `{string}`, `{boolean}`, `{array}`, `{object}`
   - Types within same group are compatible, different groups are not

**What It Doesn't Check** (proxy can differ):
- Descriptions
- Default values
- Optional fields
- Exact type matches (only compatibility)

**When Compatibility Is Checked:**
- **At Runtime**: Automatically when backend comes online (via `check_tool_compatibility()` in `compatibility.py`)
- **In Tests**: When running `test_proxy.py` (uses same `compare_tool_definitions()` function)
- **On Startup**: Proxy checks compatibility during initialization if backend is online
- **On First Tool Call**: If health check starts on first call, compatibility is checked when backend comes online

**Compatibility Check Output:**
- Logs warnings for each incompatible tool
- Provides detailed schema dumps for first incompatible tool (in logs)
- Continues operation (proxy still works, but warns about sync issues)
- Test suite shows summary: compatible count, issues count, missing/extra tools

### When Backend Changes

1. **Identify the Change**
   - What USTRUCT was modified?
   - What properties changed?
   - Are there new required fields?
   - Are required field types different?
   - Are there new optional fields? (proxy can add these too)

2. **Update Proxy Schema (Compatibility-Based)**
   - Edit the appropriate domain file:
     - Common Tools → `tool_definitions_common.py`
     - Asset Tools → `tool_definitions_asset.py`
     - Blueprint Tools → `tool_definitions_blueprint.py`
   - **Ensure compatibility**:
     - Add any new required fields
     - Update required field types to compatible types
     - Match required field names exactly (camelCase from USTRUCT)
   - **Improve where possible**:
     - Better descriptions
     - Simpler types (if appropriate, e.g., `string` instead of `enum` with one value)
     - Better defaults
     - Additional optional fields (if useful)

3. **Test Immediately**
   ```bash
   cd UnrealMCPProxy
   uv --directory . run test_proxy.py
   ```
   - This will check compatibility with backend
   - Fix any compatibility issues reported
   - The test uses the same `compare_tool_definitions()` function as runtime

4. **Verify No Warnings**
   - Start the proxy
   - Check logs for compatibility issue warnings
   - Should see: "Tool discovery completed: X tools found, all compatible"
   - If warnings appear, fix compatibility issues
   - Runtime compatibility check happens automatically when backend comes online

5. **Commit Together**
   - Commit backend changes and proxy changes in the same PR
   - Include test results in commit message
   - Note any schema improvements made in proxy

### When Adding New Tools

1. **Backend First**
   - Add USTRUCT definitions
   - Register tool in backend
   - Verify backend generates correct schema
   - Note which fields are required

2. **Add to Proxy (Compatibility-Based)**
   - Add tool definition to the appropriate domain file:
     - Common Tools → `tool_definitions_common.py`
     - Asset Tools → `tool_definitions_asset.py`
     - Blueprint Tools → `tool_definitions_blueprint.py`
   - **Ensure compatibility**:
     - Include all required fields from backend
     - Match required field names exactly
     - Use compatible types for required fields
   - **Improve where possible**:
     - Better descriptions
     - Simpler types (e.g., `string` instead of `enum` with one value)
     - Better defaults
     - Additional optional fields (if useful)

3. **Test**
   - Run test suite: `uv --directory . run test_proxy.py`
   - Verify new tool appears in both backend and proxy cache
   - Verify no compatibility issues
   - Test tool call works correctly

### When Removing Tools

1. **Backend First**
   - Remove tool registration
   - Remove USTRUCT definitions (if unused)

2. **Remove from Proxy**
   - Remove from `tool_definitions.py`
   - Update expected tool count in tests

3. **Test**
   - Run test suite
   - Verify tool no longer appears
   - Verify no "missing in backend" warnings

## Troubleshooting

### "Compatibility issue: Missing required fields"

**Possible Causes:**
- Proxy schema doesn't include all backend required fields
- Field name typo or case mismatch

**Solution:** Check backend's required fields list and ensure all are present in proxy schema with matching names.

### "Compatibility issue: Type mismatch"

**Possible Causes:**
- Proxy field type incompatible with backend type
- Type conversion needed (e.g., `number` vs `integer`)

**Solution:** Ensure field types are compatible. Compatible types: `number`/`integer`, `string`, `boolean`, `array`, `object`.

### "Tool works but test shows compatibility issues"

**Possible Causes:**
- Compatibility check is too strict
- Backend accepts parameters that aren't in schema

**Solution:** Fix compatibility issues to ensure reliable operation. Backend may accept extra parameters, but required fields must match.

### "Backend schema changed but proxy still works"

**Possible Causes:**
- Backend added optional fields (proxy doesn't need to match)
- Backend changed descriptions (proxy can have its own)
- Backend changed defaults (proxy applies its own)

**Solution:** This is expected! Proxy can have improved schemas. Only required fields and types must be compatible.

## Quick Reference Checklist

Before committing schema changes:

- [ ] Run test suite: `uv --directory . run test_proxy.py`
- [ ] All 15 tools compatible (or expected count)
- [ ] 0 compatibility issues detected
- [ ] No missing tools warnings
- [ ] No extra tools warnings
- [ ] Proxy starts without compatibility warnings
- [ ] Backend and proxy changes committed together (if backend changed)
- [ ] Test results included in commit message

## Related Documentation

- `PROXY_IMPLEMENTATION_PLAN.md` - Overall proxy architecture
- `README.md` - Proxy setup and usage
- `test_proxy.py` - Test suite implementation
- Backend: `Source/UnrealMCPServer/Public/UMCP_Types.h` - Schema generation logic

## Summary

The compatibility-based approach provides flexibility while ensuring correctness:

1. **Understanding** how the backend generates schemas and what compatibility means
2. **Synchronizing** required fields and types (compatibility requirements)
3. **Improving** schemas where possible (descriptions, types, defaults)
4. **Testing** regularly with the automated test suite
5. **Verifying** no compatibility warnings at runtime

**Key Takeaways:**
- ✅ **Synchronization is still required** - but only for compatibility requirements
- ✅ **Proxy can improve schemas** - better UX without breaking compatibility
- ✅ **Compatibility checker** - automatically verifies compatibility at runtime and in tests
- ✅ **Flexible approach** - focus on what matters (required fields, types) not exact matching

The test suite and runtime compatibility checker are your best friends - use them liberally and fix compatibility issues immediately. Remember: proxy schemas can be better than backend schemas as long as they're compatible!


